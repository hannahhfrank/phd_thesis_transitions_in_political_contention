import pandas as pdimport osimport numpy as npfrom functions import dichotomize,lag_groupped,consec_zeros_grouped,apply_decay,imp_opti,calibrate_imp,get_wb,multivariate_imp_bayes,multivariate_imp_tree,multivariate_imp_neigh,simple_imp_grouped,linear_imp_groupedimport matplotlib.pyplot as plt# List of microstates: micro_states={"Dominica":54,              "Grenada":55,              "Saint Lucia":56,              "Saint Vincent and the Grenadines":57,              "Antigua & Barbuda":58,              "Saint Kitts and Nevis":60,              "Monaco":221,              "Liechtenstein":223,              "San Marino":331,              "Andorra":232,              "Abkhazia":396,              "South Ossetia":397,              "São Tomé and Principe":403,              "Seychelles":591,              "Vanuatu":935,              "Kiribati":970,              "Nauru":971,              "Tonga":972,              "Tuvalu":973,              "Marshall Islands":983,              "Palau":986,              "Micronesia":987,              "Samoa":990}# Additional countries not included in ACLED: # 265 German Democratic Republic	# 315 Czechoslovakia# 345 Yugoslavia# 396 Abkhazia# 397 South Ossetia# 680 Yemen, People's Republic of ---> EXCLUDE# Temporal coverage: 1989--2022exclude={"German Democratic Republic":265,         "Czechoslovakia":315,         "Yugoslavia":345,         "Abkhazia":396,         "South Ossetia":397,         "Yemen, People's Republic of":680}# Countries not included in World Bank: # Or have mostly missing values    exclude2 ={"Taiwan":713, # Not included in WDI           "Bahamas":31, # Not included in vdem           "Belize":80, # Not included in vdem           "Brunei Darussalam":835, # Not included in vdem           "Kosovo":347, # Mostly missing in WDI           "Democratic Peoples Republic of Korea":731} # Mostly missing in WDI############### UCDP ###############ucdp_sb=pd.read_csv("data/data_out/ucdp_cy_sb.csv",index_col=0)df = ucdp_sb[["year","gw_codes","country","best","side_b"]][~ucdp_sb['gw_codes'].isin(list(micro_states.values())+list(exclude.values())+list(exclude2.values()))]df.columns=["year","gw_codes","country","sb_fatalities","side_b"]# Onset variabledf = df.sort_values(by=['country', 'year'])df['lag1'] = df.groupby('country')['sb_fatalities'].shift(1)df['lag2'] = df.groupby('country')['sb_fatalities'].shift(2)df['onset'] = np.where((df['sb_fatalities'] >= 25) & (df['lag1'] <25)  & (df['lag2'] <25), 1, 0)df['onset2'] = np.where((df['sb_fatalities'] >= 1000) & (df['lag1'] <1000)  & (df['lag2'] <1000), 1, 0)df = df.drop('lag1', axis=1)df = df.drop('lag2', axis=1)# t-1 model df["sb_fatalities_lag1"]=lag_groupped(df,"country","sb_fatalities",1)# Time sincedichotomize(df,"sb_fatalities","d_civil_conflict",0)df['d_civil_conflict_zeros'] = consec_zeros_grouped(df,'country','d_civil_conflict')df['d_civil_conflict_zeros_decay'] = apply_decay(df,'d_civil_conflict_zeros')df = df.drop('d_civil_conflict', axis=1)df = df.drop('d_civil_conflict_zeros', axis=1)# Neighbor conflict history sb fatalities neighbors=pd.read_csv("data/data_out/cy_neighbors.csv",index_col=0)gw_codes=pd.read_csv("data/df_ccodes_gw.csv")gw_codes_s=gw_codes.loc[gw_codes["end"]>=1989]df_neighbors=pd.merge(left=df[["year","country","gw_codes","sb_fatalities"]],right=neighbors[["gw_codes","year","neighbors"]],on=["year","gw_codes"],how="left")df_neighbors["neighbors_fat"]=0for i in range(len(df_neighbors)):    if pd.isna(df_neighbors["neighbors"].iloc[i]):         pass    else:           lst=df_neighbors["neighbors"].iloc[i].split(';')        counts=0        for x in lst:            c=int(gw_codes_s["gw_codes"].loc[gw_codes_s["country"]==x].iloc[0])            if df_neighbors["sb_fatalities"].loc[(df_neighbors["year"]==df_neighbors["year"].iloc[i])&(df_neighbors["gw_codes"]==c)].empty==False:                counts+=int(df_neighbors["sb_fatalities"].loc[(df_neighbors["year"]==df_neighbors["year"].iloc[i])&(df_neighbors["gw_codes"]==c)].iloc[0])        if counts>0:            df_neighbors.iloc[i, df_neighbors.columns.get_loc('neighbors_fat')] = counts#dichotomize(df_neighbors,"neighbors_fat","d_neighbors_sb_fatalities",0)df_neighbors['d_neighbors_sb_fatalities_lag1'] = lag_groupped(df_neighbors,'country','neighbors_fat',1)df=pd.merge(left=df,right=df_neighbors[["year","gw_codes","d_neighbors_sb_fatalities_lag1"]],on=["year","gw_codes"],how="left")########################## World Bank data ##########################df_econ=df[["year","gw_codes","country"]].copy()feat_dev = ["NY.GDP.PCAP.CD", # GDP per capita (current US$)            "NY.GDP.MKTP.KD.ZG", # GDP growth (annual %)             "SP.POP.TOTL", # Population size            "NY.GDP.PETR.RT.ZS", # Oil rents (% of GDP)            "AG.LND.PRCP.MM", # Average precipitation in depth (mm per year)            "SE.SEC.ENRR.MA", # School enrollment, secondary, male (% gross)            "GC.TAX.TOTL.GD.ZS", # Tax revenue (% of GDP)            "RQ.EST", # Regulatory Quality: Estimate            ]# Import country codes  df_ccodes = pd.read_csv("data/df_ccodes.csv")c_list=list(df_ccodes.iso_alpha3)c_list = [char for char in c_list if char != "XYZ"]# Load data economy=get_wb(list(range(1989, 2023, 1)),c_list,feat_dev)# GDP per capita base=df[["year","gw_codes","country"]].copy()base=pd.merge(left=base,right=economy[["year","gw_codes","NY.GDP.PCAP.CD"]],on=["year","gw_codes"],how="left")base_imp_final=linear_imp_grouped(base,"country",["NY.GDP.PCAP.CD"])base_imp_final=simple_imp_grouped(base_imp_final,"country",["NY.GDP.PCAP.CD"])base_imp_final = base_imp_final.rename(columns={"NY.GDP.PCAP.CD": 'gdp'})df=pd.merge(left=df,right=base_imp_final[["year","gw_codes","gdp"]],on=["year","gw_codes"],how="left")# GDP growth (annual %) base=df[["year","gw_codes","country"]].copy()base=pd.merge(left=base,right=economy[["year","gw_codes","NY.GDP.MKTP.KD.ZG"]],on=["year","gw_codes"],how="left")base_imp_final=linear_imp_grouped(base,"country",["NY.GDP.MKTP.KD.ZG"])base_imp_final=simple_imp_grouped(base_imp_final,"country",["NY.GDP.MKTP.KD.ZG"])base_imp_final = base_imp_final.rename(columns={"NY.GDP.MKTP.KD.ZG": 'growth'})df=pd.merge(left=df,right=base_imp_final[["year","gw_codes","growth"]],on=["year","gw_codes"],how="left")df=df.loc[df["country"]!="Djibouti"]# Population sizebase=df[["year","gw_codes","country"]].copy()base=pd.merge(left=base,right=economy[["year","gw_codes","SP.POP.TOTL"]],on=["year","gw_codes"],how="left")base_imp_final=linear_imp_grouped(base,"country",["SP.POP.TOTL"])base_imp_final=simple_imp_grouped(base_imp_final,"country",["SP.POP.TOTL"])base_imp_final = base_imp_final.rename(columns={"SP.POP.TOTL": 'pop'})df=pd.merge(left=df,right=base_imp_final[["year","gw_codes","pop"]],on=["year","gw_codes"],how="left")# Oil rents (% of GDP)base=df[["year","gw_codes","country"]].copy()base=pd.merge(left=base,right=economy[["year","gw_codes","NY.GDP.PETR.RT.ZS"]],on=["year","gw_codes"],how="left")base_imp_final=linear_imp_grouped(base,"country",["NY.GDP.PETR.RT.ZS"])base_imp_final=simple_imp_grouped(base_imp_final,"country",["NY.GDP.PETR.RT.ZS"])base_imp_final = base_imp_final.rename(columns={"NY.GDP.PETR.RT.ZS": 'oil'})df=pd.merge(left=df,right=base_imp_final[["year","gw_codes","oil"]],on=["year","gw_codes"],how="left")# Average precipitation in depth (mm per year)base=df[["year","gw_codes","country"]].copy()base=pd.merge(left=base,right=economy[["year","gw_codes","AG.LND.PRCP.MM"]],on=["year","gw_codes"],how="left")base_imp_final=linear_imp_grouped(base,"country",["AG.LND.PRCP.MM"])base_imp_final=simple_imp_grouped(base_imp_final,"country",["AG.LND.PRCP.MM"])base_imp_final = base_imp_final.rename(columns={"AG.LND.PRCP.MM": 'percip'})df=pd.merge(left=df,right=base_imp_final[["year","gw_codes","percip"]],on=["year","gw_codes"],how="left")df=df.loc[df["country"]!="Serbia"]df=df.loc[df["country"]!="Montenegro"]# School enrollment, secondary, male (% gross)base=df[["year","gw_codes","country"]].copy()base=pd.merge(left=base,right=economy[["year","gw_codes","SE.SEC.ENRR.MA"]],on=["year","gw_codes"],how="left")base_imp_final=linear_imp_grouped(base,"country",["SE.SEC.ENRR.MA"])base_imp_final=simple_imp_grouped(base_imp_final,"country",["SE.SEC.ENRR.MA"])base_imp_final = base_imp_final.rename(columns={"SE.SEC.ENRR.MA": 'edu'})df=pd.merge(left=df,right=base_imp_final[["year","gw_codes","edu"]],on=["year","gw_codes"],how="left")df=df.loc[df["country"]!="Azerbaijan"]df=df.loc[df["country"]!="Haiti"]df=df.loc[df["country"]!="Moldova"]df=df.loc[df["country"]!="Turkmenistan"]df=df.loc[df["country"]!="Zambia"]# Regulatory Quality: Estimatebase=df[["year","gw_codes","country"]].copy()base=pd.merge(left=base,right=economy[["year","gw_codes","RQ.EST"]],on=["year","gw_codes"],how="left")base_imp_final=linear_imp_grouped(base,"country",["RQ.EST"])base_imp_final=simple_imp_grouped(base_imp_final,"country",["RQ.EST"])base_imp_final = base_imp_final.rename(columns={"RQ.EST": 'regu'})df=pd.merge(left=df,right=base_imp_final[["year","gw_codes","regu"]],on=["year","gw_codes"],how="left")df[df.isnull().any(axis=1)].country.unique()# Average Mean Surface Air Temperature temp=pd.read_csv("data/data_out/temp_cy.csv",index_col=0)base=df[["year","gw_codes","country"]].copy()base=pd.merge(left=base,right=temp[["gw_codes","year","temp"]],on=["year","gw_codes"],how="left")base_imp_final=linear_imp_grouped(base,"country",["temp"])base_imp_final=simple_imp_grouped(base_imp_final,"country",["temp"])#base_imp_final['temp'] = base_imp_final['temp'] - base_imp_final.groupby('country')['temp'].transform('mean')df=pd.merge(left=df,right=base_imp_final[["year","gw_codes","temp"]],on=["year","gw_codes"],how="left")############## EPR ############### Ethnic fractionalizationbase=df[["year","gw_codes","country"]].copy()erp=pd.read_csv("data/data_out/epr_cy.csv",index_col=0)base=pd.merge(left=base,right=erp[["year","gw_codes","ethnic_frac"]],on=["year","gw_codes"],how="left")base_imp_final=linear_imp_grouped(base,"country",["ethnic_frac"])base_imp_final=simple_imp_grouped(base_imp_final,"country",["ethnic_frac"])df=pd.merge(left=df,right=base_imp_final[["year","gw_codes","ethnic_frac"]],on=["year","gw_codes"],how="left")# Share powerlessbase=df[["year","gw_codes","country"]].copy()base=pd.merge(left=base,right=erp[["year","gw_codes","powerless_share"]],on=["year","gw_codes"],how="left")base_imp_final=linear_imp_grouped(base,"country",["powerless_share"])base_imp_final=simple_imp_grouped(base_imp_final,"country",["powerless_share"])df=pd.merge(left=df,right=base_imp_final[["year","gw_codes","powerless_share"]],on=["year","gw_codes"],how="left")############### UNDP ################ Expected years of schooling, male#hdi=pd.read_csv("data/data_out/hdi_cy.csv",index_col=0)#base=df[["year","gw_codes","country"]].copy()#base=pd.merge(left=base,right=hdi[["year","gw_codes",'eys_male']],on=["year","gw_codes"],how="left")#base_imp_final=linear_imp_grouped(base,"country",["eys_male"])#base_imp_final=simple_imp_grouped(base_imp_final,"country",["eys_male"])#df=pd.merge(left=df,right=base_imp_final[["year","gw_codes","eys_male"]],on=["year","gw_codes"],how="left")#df=df.loc[df["country"]!="Somalia"]################ V-Dem ################# Liberal democracy indexvdem=pd.read_csv("data/data_out/vdem_cy.csv",index_col=0)base=df[["year","gw_codes","country"]].copy()base=pd.merge(left=base,right=vdem[["year","gw_codes","v2x_libdem"]],on=["year","gw_codes"],how="left")base_imp_final=linear_imp_grouped(base,"country",["v2x_libdem"])base_imp_final=simple_imp_grouped(base_imp_final,"country",["v2x_libdem"])base_imp_final = base_imp_final.rename(columns={"v2x_libdem": 'libdem'})df=pd.merge(left=df,right=base_imp_final[["year","gw_codes","libdem"]],on=["year","gw_codes"],how="left")# Electoral democracy indexvdem=pd.read_csv("data/data_out/vdem_cy.csv",index_col=0)base=df[["year","gw_codes","country"]].copy()base=pd.merge(left=base,right=vdem[["year","gw_codes","v2x_polyarchy"]],on=["year","gw_codes"],how="left")base_imp_final=linear_imp_grouped(base,"country",["v2x_polyarchy"])base_imp_final=simple_imp_grouped(base_imp_final,"country",["v2x_polyarchy"])base_imp_final = base_imp_final.rename(columns={"v2x_polyarchy": 'polyarchy'})df=pd.merge(left=df,right=base_imp_final[["year","gw_codes","polyarchy"]],on=["year","gw_codes"],how="left")# Regime durationvdem=pd.read_csv("data/data_out/vdem_cy.csv",index_col=0)base=df[["year","gw_codes","country"]].copy()base=pd.merge(left=base,right=vdem[["year","gw_codes","v2regdur"]],on=["year","gw_codes"],how="left")base_imp_final=linear_imp_grouped(base,"country",["v2regdur"])base_imp_final=simple_imp_grouped(base_imp_final,"country",["v2regdur"])base_imp_final = base_imp_final.rename(columns={"v2regdur": 'stability'})df=pd.merge(left=df,right=base_imp_final[["year","gw_codes","stability"]],on=["year","gw_codes"],how="left")# Bahamas, Barbados, Belize, Malte, Serbia, Kosovo, Iceland, Maldives, Vietnam, Brunei Darussalampolity = pd.read_excel("data/p5v2018.xls")polity=polity[["year","ccode","country",'polity2']].loc[polity["year"]>=1989]polity.columns=["year","gw_codes","country",'polity2']polity=polity.reset_index(drop=True)base=pd.merge(left=df,right=polity[["year","gw_codes","polity2"]],on=["year","gw_codes"],how="left")### Simple ###polity_imp=linear_imp_grouped(base,"country",["polity2"])polity_imp=simple_imp_grouped(polity_imp,"country",["polity2"])# Validate#for c in base.country.unique():#    fig, axs = plt.subplots(1, 2, figsize=(10, 5))#    axs[0].plot(base["year"].loc[base["country"]==c], base["polity2"].loc[base["country"]==c])#    axs[1].plot(polity_imp["year"].loc[polity_imp["country"]==c], polity_imp["polity2"].loc[polity_imp["country"]==c])#    axs[0].set_title(c)#    plt.show()polity_imp = polity_imp[~polity_imp['country'].isin(["Bahamas","Barbados","Belize","Malta","Serbia","Kosovo","Iceland","Maldives","Vietnam","Brunei Darussalam"])] df = df[~df['country'].isin(["Bahamas","Barbados","Belize","Malta","Serbia","Kosovo","Iceland","Maldives","Vietnam","Brunei Darussalam"])] df=pd.merge(left=df,right=polity_imp[["year","gw_codes","polity2"]],on=["year","gw_codes"],how="left")# Terrain Ruggedness Indexbase=df[["year","gw_codes","country"]].copy()rug=pd.read_csv("data/data_out/rug_cy.csv",index_col=0)base=pd.merge(left=base,right=rug[["year","gw_codes","rugged"]],on=["year","gw_codes"],how="left")df=pd.merge(left=df,right=base[["year","gw_codes","rugged"]],on=["year","gw_codes"],how="left")# Fearon and Laitinfl = pd.read_csv("data/fl_missings.csv",index_col=0)fl=fl[["ccode","country","year","mtnest"]]terrain = fl[['ccode','mtnest']].drop_duplicates()terrain.columns=["gw_codes","terrain_fl"]# Missing: 'Suriname', 'Luxembourg', 'Cabo Verde', 'Equatorial Guinea','Comoros', 'South Sudan', 'Qatar', 'East Timor', 'Solomon Islands'# Fill with zerodf=pd.merge(left=df,right=terrain[["gw_codes","terrain_fl"]],on=["gw_codes"],how="left")df['terrain_fl'].fillna(0, inplace=True) # Save print(df.isnull().any())df.to_csv("data/df_interpret.csv")